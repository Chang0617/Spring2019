{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data and Uncertainty\n",
    "\n",
    "## Models and Data\n",
    "\n",
    "- In probability, underlying processes are represented by a __model__ (often some distribution)   \n",
    "    e.g., flipping a coin, rolling a dice, etc.\n",
    "    \n",
    "- In reality, even for very simple processes, underlying process is not easily described   \n",
    "    e.g., what is the true $p$ of a coin? pmf of a dice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Many real-world processes are much more complicated; however, we still try  \n",
    "\n",
    "    > _Now it would be very remarkable if any system existing in the real world could be \n",
    "    exactly represented by any simple model. However, cunningly chosen parsimonious models \n",
    "    often do provide remarkably useful approximations. \n",
    "    [... example of modeling gas in physics ...]  \n",
    "    For such a model there is no need to ask the question \"Is the model true?\". \n",
    "    If \"truth\" is to be the \"whole truth\" the answer must be \"No\". \n",
    "    The only question of interest is \"Is the model illuminating and useful?\"._  \n",
    "    George Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "    \n",
    "- In era of data science, do models matter?  \n",
    "    _Yes! We can simulate the real world to test our algorithms_\n",
    "\n",
    "- For a random variable $X$ with a known distribution $p(x)$, we can determine the distribution of $Y = f(X)$\n",
    "\n",
    "- We can vary choice of $f$ to test our learning strategy: e.g., $f$ can be linear, quadratic, etc.\n",
    "\n",
    "- If our learning model doesn't work for simple simulated data, it won't work well for complex real data\n",
    "\n",
    "- If our chosen model is accurate/useful, we can say a lot about the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- However, often building models from ground up is practically impossible\n",
    "\n",
    "- e.g., where do you begin to build a model for NCAA tournament? human behavior?\n",
    "\n",
    "- Often we are interested in inference and/or prediction\n",
    "\n",
    "    - __Inference__: making conclusions based on data  \n",
    "        e.g., parameters such as winning probability for each team\n",
    "\n",
    "    - __Prediction__: making guesses about the next outcome  \n",
    "        e.g., who will win?\n",
    "        \n",
    "- Monte Carlo simulation is a good tool to for mimicing the data generating process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monte Carlo simulation\n",
    "\n",
    "### Random variables\n",
    "\n",
    "- Suppose a random variable $X$ is Bernoulli(0.2)\n",
    "\n",
    "- Random variable $X$ is symbolic: i.e. $X$ does not have a single value\n",
    "\n",
    "- An observation $x$ has a value: i.e., 0 or 1 \n",
    "\n",
    "- To express a distribution of $X$, multiple observations must be used:  \n",
    "\n",
    "    e.g., $x_1, x_2, \\dots, x_s$ or a vector of $s$ observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Random sample\n",
    "\n",
    "- What is a random sample?\n",
    "\n",
    "- Recall the definition of a random sample:  \n",
    "\n",
    "    > __Random sample__: Let $X_1,X_2,\\dots,X_n$ be a set of $n$ independent random variables, all having the _same pdf_, $f_X$. Then $X_1,X_2,\\dots,X_n$ are said to be a _random sample of size $n$_.\n",
    "\n",
    "- _Random sample_ is a collection of $n$ random variables: $X_1,X_2,\\dots,X_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Expressing each rv $X_i$ with $s$ observations, we need a matrix of observations\n",
    "\n",
    "- i.e., capturing randomness of _random sample_ with _iid observations_, \n",
    "    we can generate many sets of random measurements   \n",
    "    $$\n",
    "    x_1^{(1)},x_2^{(1)},\\dots,x_n^{(1)}\\\\\n",
    "    x_1^{(2)},x_2^{(2)},\\dots,x_n^{(2)}\\\\\n",
    "    \\vdots\\\\\n",
    "    x_1^{(s)},x_2^{(s)},\\dots,x_n^{(s)}\n",
    "    $$\n",
    "\n",
    "- As an example, let's simulate convergence of the sample mean to the true mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consistency of the sample mean: dice example\n",
    "\n",
    "- Suppose that $X_1,X_2,\\dots,X_n$ is a random sample of size $n$ from a discrete pdf $p_X(x;\\mu)$\n",
    "\n",
    "- Suppose $p_X$ is nice: i.e., $E(X)=\\mu$ and $\\text{Var}(X) = \\sigma^2 < \\infty$\n",
    "\n",
    "- Question: can we estimate $E(X)$ with $\\hat\\mu_n = \\frac{1}{n}\\sum_i^n X_i$? \n",
    "\n",
    "- Can $\\hat\\mu_n$ be shown to be a consistent estimator for $\\mu$ empirically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Since we are simulating dice throw with a pmf, the _model_ is perfect\n",
    "\n",
    "- True value of $E(X)=\\mu=3.5$ and $\\text{Var}(X) = \\sigma^2 = 2.917$\n",
    "\n",
    "- The sampling distribution gives $E(\\hat\\mu_n)=\\mu$ and $$\\text{Var}(\\hat\\mu_n) = \\text{Var}\\left(\\frac{1}{n}\\sum_{i=1}^n X_i \\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i)= \\frac{\\sigma^2}{n}$$\n",
    "\n",
    "- We will verify this empirically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Digression: numpy and array arithmetic\n",
    "\n",
    "- Generate many random observations $(x_1^{(s)},x_2^{(s)},\\dots ,x_n^{(s)})$ for $s=1,2,\\dots, 10$ and $n=7$\n",
    "\n",
    "- Each simulation is the _data_ of 7 dice throws\n",
    "\n",
    "- Put them into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n = 7\n",
    "S = 10\n",
    "\n",
    "x = np.random.randint(size=(S, n), low=1, high=7)\n",
    "print(\"shape of x:\", x.shape)\n",
    "print(\"unique values in x:\", np.unique(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In `x`, one set of observations is one row. Get one row by indexing into `x`. First index is for the row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x ## 10 rows (observations), 7 columns (random sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"one row:\", x[0])    \n",
    "print(\"one value:\", x[0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"one row:\", x[-1])\n",
    "print(\"one value:\", x[-1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Numpy offers many convenient and flexible ways to slice and get a subset of numpy arrays (Chapter 2 in Vanderplas)\n",
    "\n",
    "- In particular, [_views_ of arrays](https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html#Subarrays-as-no-copy-views) are useful. This is in contrast to R that always creates copies (even in function calls).\n",
    "\n",
    "- Numpy makes array operations simple. For example, we can't use add a value to the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## [1,2,3] + 3        ## causes error\n",
    "np.array([10,20,30]) + 3 ## works fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In addition to common arithmetic functions (called ufuncs) other useful functions are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.multiply.outer([1,2,3], [10,20,30]) ## outer product of first two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.add.outer([1,2,3], [10,20,30]) ## outer sum of first two columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that sample mean of one set of random observations can be computed by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"object method:\", x[0].mean(), \"function:\", np.mean(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Internally, they are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x0 = x[0]\n",
    "# x0.mean??\n",
    "# np.mean??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- One row of `x` is one simulation: i.e., 7 dice throws. \n",
    "\n",
    "- One column of `x` is all 10 simulations for random variable $X_1$\n",
    "\n",
    "- How do you compute mean of each simulation?\n",
    "\n",
    "- Numpy `axis` refers to the direction of the array. \n",
    "\n",
    "- Giving argument `axis=0`, the mean function computes column averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "temp = x.mean(axis=0)\n",
    "print(\"x.mean(axis=0)   :\", temp)\n",
    "print(\"temp.mean(0)[3]  :\", temp[3])\n",
    "print(\"temp[:,3].mean() :\", x[:,3].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Giving argument `axis=1`, the mean function computes row averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "xmean = x.mean(axis=1)\n",
    "print(\"xmean:\", xmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Plot the histogram of `xmean`:   \n",
    "\n",
    "_Note that `xmean` does not contain many observations of the sample mean $\\hat\\mu_n$_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # set plot style\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(11, 9)\n",
    "plt.hist(xmean)\n",
    "plt.xlabel('sample mean')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Effect of Sample Size $n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Chebyshev's inequality says that \n",
    "$$ \\Pr(|\\hat\\mu_n - \\mu| < \\epsilon) > 1 - \\frac{\\text{Var}(\\hat\\mu_n)}{\\epsilon^2} \n",
    "= 1- \\frac{\\sigma^2}{n\\epsilon^2} $$\n",
    "\n",
    "Recall that $\\sigma^2=2.917$ is the variance of outcomes of dice represented as a random variable. \n",
    "Fixing the error to $\\epsilon = 1$ makes the RHS a function of $n$.\n",
    "\n",
    "In order to empirically verify Chebyshev's inequality, we will simulate the dice with a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## throw dice\n",
    "def throw_dice(n=1):\n",
    "    \n",
    "    from numpy.random import randint\n",
    "    \n",
    "    return(randint(size=n, low=1, high=7))\n",
    "\n",
    "## throw dice n times, compute mean\n",
    "def muhat_n(n=1):\n",
    "    \n",
    "    return(throw_dice(n).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Above functions return numpy arrays. We will compile results below in a bare list. Then create Pandas data frame from it (more on Pandas later). Some automatic type conversion is possible, but more strict than R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n_choices = np.arange(20, 10001, 10)\n",
    "\n",
    "results = []\n",
    "for n in n_choices:\n",
    "    results += [muhat_n(n)] ## appends to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'n_throws': n_choices,\n",
    "    'muhat_n' : results,\n",
    "})\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "figsize(11, 9)\n",
    "plt.plot(df['n_throws'], df['muhat_n']);\n",
    "plt.xlabel(\"Number of dice throws (n)\");\n",
    "plt.ylabel(\"Average of n dice throws\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can build on the result by showing where 95% bound according to Chebyshev's inequality.\n",
    "\n",
    "If we choose $\\epsilon = 1$ and $n$ is fixed at 50. Then, plugging in $\\sigma^2$, we get:\n",
    "$$ \n",
    "1- \\frac{2.917}{n\\cdot \\epsilon^2} = 0.95\\\\\n",
    "\\epsilon = \\sqrt{\\frac{2.917}{0.05\\cdot n}}$$\n",
    "\n",
    "Following computes error threshold $\\epsilon$ guaranteed by Chebyshev's threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "epsilon_n = np.sqrt(2.917/(0.05*n_choices))\n",
    "df['epsilon'] = epsilon_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Plot the new plot\n",
    "$$ \\Pr(|\\hat\\mu_n - \\mu| < \\epsilon) > 0.95\\\\\n",
    "\\Pr(-\\epsilon_n < \\hat\\mu_n - \\mu < \\epsilon_n)  > 0.95 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "figsize(11, 9)\n",
    "plt.plot((df['n_throws']),  df['muhat_n']-3.5);    ## subtract true mean 3.5\n",
    "plt.plot((df['n_throws']),  df['epsilon'], '--r');\n",
    "plt.plot((df['n_throws']), -df['epsilon'], '--r');\n",
    "plt.xlabel(\"Number of dice throws (n)\");\n",
    "plt.ylabel(\"Average of n dice throws\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## repeat computing mean of n throws s times\n",
    "def repeat_muhat_n(n=1, s=100):\n",
    "    \n",
    "    out = [muhat_n(n) for one in range(s)]\n",
    "    \n",
    "    return({ 'min': min(out), 'max': max(out), 'mean': sum(out)/s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "repeat_muhat_n(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for n in n_choices:\n",
    "    results += [repeat_muhat_n(n)] ## appends to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(results)\n",
    "df_new['n_throws'] = n_choices\n",
    "df_new['epsilon'] = epsilon_n\n",
    "df_new[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "figsize(11, 9)\n",
    "plt.plot((df_new['n_throws']),  df_new['mean']-3.5, '-g');    ## subtract true mean 3.5\n",
    "plt.plot((df_new['n_throws']),  df_new['min'] -3.5, ':g');    ## subtract true mean 3.5\n",
    "plt.plot((df_new['n_throws']),  df_new['max'] -3.5, ':g');    ## subtract true mean 3.5\n",
    "plt.plot((df_new['n_throws']),  df_new['epsilon'], '--r');\n",
    "plt.plot((df_new['n_throws']), -df_new['epsilon'], '--r');\n",
    "plt.xlabel(\"Number of dice throws (n)\");\n",
    "plt.ylabel(\"Average of n dice throws\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plot 80% and 90% bounds\n",
    "\n",
    "Plot $\\epsilon$ bounds corresponding to 80% and 90% probability. Interpret these bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "epsilon_n = np.sqrt(2.917/(0.1*n_choices))\n",
    "df_new['epsilon_10'] = epsilon_n\n",
    "\n",
    "epsilon_n = np.sqrt(2.917/(0.2*n_choices))\n",
    "df_new['epsilon_20'] = epsilon_n\n",
    "\n",
    "figsize(11, 9)\n",
    "plt.plot((df_new['n_throws']),  df_new['mean']-3.5, '-g')    ## subtract true mean 3.5\n",
    "plt.plot((df_new['n_throws']),  df_new['min'] -3.5, ':g')    ## subtract true mean 3.5\n",
    "plt.plot((df_new['n_throws']),  df_new['max'] -3.5, ':g')    ## subtract true mean 3.5\n",
    "plt.plot((df_new['n_throws']),  df_new['epsilon'], '--r')\n",
    "plt.plot((df_new['n_throws']), -df_new['epsilon'], '--r')\n",
    "plt.plot((df_new['n_throws']),  df_new['epsilon_10'], '--b')\n",
    "plt.plot((df_new['n_throws']), -df_new['epsilon_10'], '--b')\n",
    "plt.plot((df_new['n_throws']),  df_new['epsilon_20'], '--k')\n",
    "plt.plot((df_new['n_throws']), -df_new['epsilon_20'], '--k')\n",
    "plt.xlim(0, 3000)\n",
    "plt.xlabel(\"Number of dice throws (n)\")\n",
    "plt.ylabel(\"Average of n dice throws\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sampling from distribution vs data\n",
    "\n",
    "In simulation, we \"sample\" from the distribution: i.e., observe more measurements from the true underlying process. \n",
    "\n",
    "In the dice example, sampling from the distribution (true underlying process) is equivalent to the ability to execute the function `throw_dice()`. \n",
    "\n",
    "However, in real-world scenarios, we may not have that luxury: e.g., only be able to record some real dice 1000 times.\n",
    "\n",
    "In this section, we simulate such situation. There is some loaded dice with pmf as follows:\n",
    "\n",
    "|Outcome: $x$   |1     |2     |3     |4     |5     |6     |\n",
    "|------------   |---   |---   |---   |---   |---   |---   |\n",
    "|$${\\Pr(X=x)}$$ |1/12  |2/12  |2/12  |2/12  |2/12  |3/12  |\n",
    "\n",
    "Function for throwing such dice can be written as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def throw_loaded_dice(n=1):\n",
    "    from numpy.random import choice\n",
    "    \n",
    "    d = [1, 2,2, 3,3, 4,4, 5,5, 6,6,6]\n",
    "    return(choice(d, n, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What `d` represents is if one were to throw dice 12 times, one would get 1 exactly once, 2 exactly twice, 3 exactly twice, $\\dots$, 6 exactly three times. In terms of proportion (out of 12 times), you get exactly $\\Pr(X=x)$.\n",
    "\n",
    "Now we 'throw' the dice 10,000 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data = throw_loaded_dice(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In real-world situations, we may not have access to the real dice; however, we are given record of 100000 dice throws.\n",
    "\n",
    "In this case, we can _resample with replacement_ from the data. The data is our _empirical dice_ since we have 10,000 throws, each adding to count of one of the numbers 1 through 6.\n",
    "\n",
    "We can use the following function to sample from our _data_ instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def choose_from_data(n=1, data_in=None):\n",
    "    from numpy.random import choice\n",
    "    \n",
    "    return(choice(data_in, n, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's sample from `data` 1000 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pseudo_data = choose_from_data(1000, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can compare the distribution of the _true_ pmf, _empirical_ pmf, and _resampled_ pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "outcome, data_counts = np.unique(data, return_counts=True)\n",
    "outcome, resample_counts = np.unique(pseudo_data, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pmfs = pd.DataFrame({\n",
    "    'outcome': np.arange(1, 7),\n",
    "    'true_pmf': np.array([1, 2, 2, 2, 2, 3])/12,\n",
    "    'empirical_pmf': data_counts/sum(data_counts),\n",
    "    'resample_pmf': resample_counts/sum(resample_counts),\n",
    "}, columns=['outcome','true_pmf','empirical_pmf','resample_pmf'])\n",
    "\n",
    "pmfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Above experiment shows that empirical pmf and resample pmf are similar to the truth. This is the basis for using resampled data (such as bootstrap) for estimating sampling distributions, etc. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
